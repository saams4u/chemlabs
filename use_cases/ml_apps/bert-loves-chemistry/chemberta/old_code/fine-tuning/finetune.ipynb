{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "higher-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "from chemberta.utils.molnet_dataloader import load_molnet_dataset\n",
    "from datasets import load_metric\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, RobertaConfig, Trainer, TrainingArguments\n",
    "\n",
    "from chemberta.utils.roberta_regression import RobertaForRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brave-maria",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'split' is deprecated.  Use 'splitter' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tasks ['measured log solubility in mols per litre'] from available tasks for delaney: ['measured log solubility in mols per litre']\n"
     ]
    }
   ],
   "source": [
    "# tasks, (train_df, valid_df, test_df), transformers = load_molnet_dataset(\"tox21\", tasks_wanted=['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'], df_format=\"chemprop\")\n",
    "\n",
    "tasks, (train_df, valid_df, test_df), transformers = load_molnet_dataset(\"delaney\", split=\"scaffold\", df_format=\"chemprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687b5087-1d6e-4167-9ac5-efd8b62d3c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>measured log solubility in mols per litre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(C)=CCCC(C)=CC=O</td>\n",
       "      <td>0.390413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=CCCC</td>\n",
       "      <td>0.090421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCCCCCCCCCCC</td>\n",
       "      <td>-2.464346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)Cl</td>\n",
       "      <td>0.704920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCC(C)CO</td>\n",
       "      <td>1.159746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>CC(=O)OCC(=O)C1(O)CCC2C3CCC4=CC(=O)CCC4(C)C3C(...</td>\n",
       "      <td>-0.649881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>c1ccc2nc3ccccc3cc2c1</td>\n",
       "      <td>-0.388598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Nc1cccc2nc3ccccc3cc12</td>\n",
       "      <td>-0.654719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>C1CCCCCC1</td>\n",
       "      <td>-0.311180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>OC1CCCCCC1</td>\n",
       "      <td>0.961365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                smiles  \\\n",
       "0                                   CC(C)=CCCC(C)=CC=O   \n",
       "1                                               C=CCCC   \n",
       "2                                       CCCCCCCCCCCCCC   \n",
       "3                                              CC(C)Cl   \n",
       "4                                             CCC(C)CO   \n",
       "..                                                 ...   \n",
       "897  CC(=O)OCC(=O)C1(O)CCC2C3CCC4=CC(=O)CCC4(C)C3C(...   \n",
       "898                               c1ccc2nc3ccccc3cc2c1   \n",
       "899                              Nc1cccc2nc3ccccc3cc12   \n",
       "900                                          C1CCCCCC1   \n",
       "901                                         OC1CCCCCC1   \n",
       "\n",
       "     measured log solubility in mols per litre  \n",
       "0                                     0.390413  \n",
       "1                                     0.090421  \n",
       "2                                    -2.464346  \n",
       "3                                     0.704920  \n",
       "4                                     1.159746  \n",
       "..                                         ...  \n",
       "897                                  -0.649881  \n",
       "898                                  -0.388598  \n",
       "899                                  -0.654719  \n",
       "900                                  -0.311180  \n",
       "901                                   0.961365  \n",
       "\n",
       "[902 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e857223-98e2-4de7-b9ab-e82337e451a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('seyonec/SMILES_tokenized_PubChem_shard00_160k', max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf5f8b9-3222-42d2-aaae-4aac221cb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_df[\"smiles\"].tolist(), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_df[\"smiles\"].tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_df[\"smiles\"].tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e75dcfb-d370-4391-8eed-1ae8afff7b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5827e757-37d9-4aa3-a088-4b9734c0c2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"is_gpu\": true,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 515,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 2,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.5.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 600\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(\"/home/ubuntu/chemberta_models/mlm/sm_015/\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04f3673-430c-4a02-affb-d5da306e3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df.iloc[:, 1:].values.flatten()\n",
    "valid_labels = valid_df.iloc[:, 1:].values.flatten()\n",
    "test_labels = test_df.iloc[:, 1:].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7f84408-d705-4ab2-a3ea-350e9ffca977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MolNetDataset(train_encodings, train_labels)\n",
    "valid_dataset = MolNetDataset(valid_encodings, valid_labels)\n",
    "test_dataset = MolNetDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28b4e5f-cbd1-488a-920f-308fda3a81db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb730ea-a77a-4207-ac1e-fd9f00ebe6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_labels = 1\n",
    "config.norm_mean = [np.mean(np.array(train_labels), axis=0)]\n",
    "config.norm_std = [np.std(np.array(train_labels), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40ef978e-070e-4ed5-a35d-39e183bea852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/ubuntu/chemberta_models/mlm/sm_015/ were not used when initializing RobertaForRegression: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForRegression from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForRegression from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForRegression were not initialized from the model checkpoint at /home/ubuntu/chemberta_models/mlm/sm_015/ and are newly initialized: ['norm_mean', 'norm_std', 'regression.dense.weight', 'regression.dense.bias', 'regression.out_proj.weight', 'regression.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForRegression.from_pretrained(\"/home/ubuntu/chemberta_models/mlm/sm_015/\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bae8f665-16ef-4737-9b14-4cf3b619b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    per_device_train_batch_size=64,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0883781-bc37-4e6f-b052-556579720b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find file locally at pearsonr/pearsonr.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.6.2/metrics/pearsonr/pearsonr.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/metrics/pearsonr/pearsonr.py.\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"pearsonr\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    return metric.compute(predictions=logits.reshape(-1, 1), references=labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9741bf09-b0f5-4679-b1e3-7f19d2f79f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=valid_dataset,             # evaluation dataset\n",
    "#     compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9c9fbb3-f17d-445e-aa58-53017eab0987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.645300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=0.5636265595753988, metrics={'train_runtime': 35.8605, 'train_samples_per_second': 0.418, 'total_flos': 8372078089452.0, 'epoch': 1.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 467853312, 'train_mem_cpu_peaked_delta': 1497989120})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6daa4a59-c3b3-48af-a8a4-9e479fc68903",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9973b234-ad5d-46d4-bee1-6972e522d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64ea6d76-4090-401b-8534-14a76ab4d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5578841183758808, 1.369558395877492e-10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(predictions.predictions.flatten(), predictions.label_ids.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ba9cc-6835-4639-8618-6f9487b9c5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
