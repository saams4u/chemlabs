{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2xgoyPJvq78"
   },
   "source": [
    "## Bayesian neural network with pretrained protein embedding enhances prediction accuracy of drug-protein interaction\n",
    "\n",
    "ABSTRACT: The characterization of drug-protein interactions is crucial in the high-throughput screening for drug\n",
    "discovery. The deep learning-based approaches have attracted attention because they can predict\n",
    "drug-protein interactions without trial-and-error by humans. However, because data labeling requires\n",
    "significant resources, the available protein data size is relatively small, which consequently decreases\n",
    "model performance. Here we propose two methods to construct a deep learning framework that exhibits\n",
    "superior performance with a small labeled dataset. At first, we use transfer learning in encoding protein\n",
    "sequences with a pretrained model, which trains general sequence representations in an unsupervised\n",
    "manner. Second, we use a Bayesian neural network to make a robust model by estimating the data\n",
    "uncertainty. As a result, our model performs better than the previous baselines for predicting drugprotein interactions. We also show that the quantified uncertainty from the Bayesian inference is related\n",
    "to the confidence and can be used for screening DPI data points.\n",
    "\n",
    "Link to paper: https://arxiv.org/pdf/2012.08194v2.pdf\n",
    "\n",
    "Credit: https://github.com/QHwan/PretrainDPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps2VKk1fu5rG",
    "outputId": "901b7842-0199-4cb1-888b-25b957755102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/PretrainDPI\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository and cd into directory\n",
    "!git clone https://github.com/QHwan/PretrainDPI.git\n",
    "%cd PretrainDPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOh061mWwjb6"
   },
   "outputs": [],
   "source": [
    "# Install dependencies / requirements\n",
    "!pip install rdkit-pypi==2021.3.1.5 fair-esm\n",
    "!pip install torch==1.4.0\n",
    "!pip install torch-geometric \\\n",
    "  torch-sparse==latest+cu101 \\\n",
    "  torch-scatter==latest+cu101 \\\n",
    "  torch-cluster==latest+cu101 \\\n",
    "  -f https://pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0brxv6XIwWvW"
   },
   "source": [
    "This code classifies binary drug-protein interaction data with the pretrained protein embedding and Bayesian neural networks.\n",
    "\n",
    "At first, one needs to convert raw data format into deep learning-ready. In the `./data` folder, run `preprocess.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87OyeItsvrf5",
    "outputId": "ea0ccd3e-494e-4be8-86b4-0e4007b6488c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/PretrainDPI/data\n",
      "Number of pairs: 6727\n",
      "Number of positive interactions: 3369\n",
      "Number of negative interactions: 3358\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm1_t12_85M_UR50S.pt\" to /root/.cache/torch/hub/checkpoints/esm1_t12_85M_UR50S.pt\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm1_t12_85M_UR50S-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm1_t12_85M_UR50S-contact-regression.pt\n",
      "  2% 52/3364 [03:56<6:30:46,  7.08s/it]tcmalloc: large alloc 1987010560 bytes == 0x560bd3ff0000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b11ea853 0x7fc8b09ee9cf 0x7fc8b119c48a 0x7fc8b08adf99 0x7fc8b08b1337 0x7fc8b08b1428 0x7fc8b0f73bff 0x7fc8b0d23846 0x7fc8b0d2a76f 0x7fc8b2531e58 0x7fc8b253217f 0x7fc8b1175a86 0x7fc8b117b0af 0x7fc8c22bf92b 0x560b74a2ecc0 0x560b74a2ea50 0x560b74aa2be0 0x560b74a9d4ae 0x560b74a303ea 0x560b74a9f32a 0x560b74a9d4ae 0x560b74a30c9f 0x560b74a30ea1 0x560b74a9fbb5 0x560b74a9d4ae 0x560b74a30c9f 0x560b74a73fd9\n",
      "tcmalloc: large alloc 1987010560 bytes == 0x560c4a6e6000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b06068e6 0x7fc8b0a68dd9 0x7fc8b0f7377a 0x7fc8b0f3eef9 0x7fc8b0ef5657 0x7fc8b0d99929 0x7fc8b0a726a2 0x7fc8b1070882 0x7fc8b0ef6609 0x7fc8b0d9be7e 0x7fc8b0a731dd 0x7fc8b0f7515e 0x7fc8b0dfc612 0x7fc8b2665a6a 0x7fc8b2665cbe 0x7fc8b11b39d2 0x7fc8b0a40c4d 0x7fc8b1094592 0x7fc8b10945f3 0x7fc8b0ee21cb 0x7fc8b1180793 0x7fc8c20ebf50 0x560b74a2ecc0 0x560b74b1ffed 0x560b74aa2988 0x560b74a9d4ae 0x560b74a303ea\n",
      "tcmalloc: large alloc 1987010560 bytes == 0x560bd3ff0000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b06068e6 0x7fc8b0a68dd9 0x7fc8b0f7377a 0x7fc8b0f3eef9 0x7fc8b0ef5657 0x7fc8b0d99929 0x7fc8b0a726a2 0x7fc8b09fbd14 0x7fc8b0f74ba3 0x7fc8b0ee4904 0x7fc8b0d4f079 0x7fc8b24c9534 0x7fc8b24c9873 0x7fc8b0ee4904 0x7fc8b0d4f079 0x7fc8b09fb780 0x7fc8b108cb00 0x7fc8b108cb52 0x7fc8b0ef2054 0x7fc8b1196915 0x7fc8c20b8e4f 0x560b74a2ecc0 0x560b74b1ffed 0x560b74aa2988 0x560b74a9d4ae 0x560b74a303ea 0x560b74a9f32a\n",
      "tcmalloc: large alloc 1987010560 bytes == 0x560bd3ff0000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b11ea853 0x7fc8b09ee9cf 0x7fc8b119c48a 0x7fc8b08adf99 0x7fc8b08b1337 0x7fc8b08b1428 0x7fc8b0f73bff 0x7fc8b0d23846 0x7fc8b0d2a76f 0x7fc8b2531e58 0x7fc8b253217f 0x7fc8b1175a86 0x7fc8b117b0af 0x7fc8c22bf92b 0x560b74a2ecc0 0x560b74a2ea50 0x560b74aa2be0 0x560b74a9d4ae 0x560b74a303ea 0x560b74a9f32a 0x560b74a9d4ae 0x560b74a30c9f 0x560b74a30ea1 0x560b74a9fbb5 0x560b74a9d4ae 0x560b74a30c9f 0x560b74a73fd9\n",
      "tcmalloc: large alloc 1987010560 bytes == 0x560c4a6e6000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b06068e6 0x7fc8b0a68dd9 0x7fc8b0f7377a 0x7fc8b0f3eef9 0x7fc8b0ef5657 0x7fc8b0d99929 0x7fc8b0a726a2 0x7fc8b1070882 0x7fc8b0ef6609 0x7fc8b0d9be7e 0x7fc8b0a731dd 0x7fc8b0f7515e 0x7fc8b0dfc612 0x7fc8b2665a6a 0x7fc8b2665cbe 0x7fc8b11b39d2 0x7fc8b0a40c4d 0x7fc8b1094592 0x7fc8b10945f3 0x7fc8b0ee21cb 0x7fc8b1180793 0x7fc8c20ebf50 0x560b74a2ecc0 0x560b74b1ffed 0x560b74aa2988 0x560b74a9d4ae 0x560b74a303ea\n",
      "tcmalloc: large alloc 1987010560 bytes == 0x560bd3ff0000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b06068e6 0x7fc8b0a68dd9 0x7fc8b0f7377a 0x7fc8b0f3eef9 0x7fc8b0ef5657 0x7fc8b0d99929 0x7fc8b0a726a2 0x7fc8b09fbd14 0x7fc8b0f74ba3 0x7fc8b0ee4904 0x7fc8b0d4f079 0x7fc8b24c9534 0x7fc8b24c9873 0x7fc8b0ee4904 0x7fc8b0d4f079 0x7fc8b09fb780 0x7fc8b108cb00 0x7fc8b108cb52 0x7fc8b0ef2054 0x7fc8b1196915 0x7fc8c20b8e4f 0x560b74a2ecc0 0x560b74b1ffed 0x560b74aa2988 0x560b74a9d4ae 0x560b74a303ea 0x560b74a9f32a\n",
      " 79% 2660/3364 [2:56:21<26:36,  2.27s/it]tcmalloc: large alloc 2438070272 bytes == 0x560bd3ff0000 @  0x7fc8e5d51b6b 0x7fc8e5d71379 0x7fc87392225e 0x7fc8739239d2 0x7fc8b11ea853 0x7fc8b09ee9cf 0x7fc8b119c48a 0x7fc8b08adf99 0x7fc8b08b1337 0x7fc8b08b1428 0x7fc8b0f73bff 0x7fc8b0d23846 0x7fc8b0d2a76f 0x7fc8b2531e58 0x7fc8b253217f 0x7fc8b1175a86 0x7fc8b117b0af 0x7fc8c22bf92b 0x560b74a2ecc0 0x560b74a2ea50 0x560b74aa2be0 0x560b74a9d4ae 0x560b74a303ea 0x560b74a9f32a 0x560b74a9d4ae 0x560b74a30c9f 0x560b74a30ea1 0x560b74a9fbb5 0x560b74a9d4ae 0x560b74a30c9f 0x560b74a73fd9\n",
      "100% 3364/3364 [3:36:23<00:00,  3.86s/it]\n",
      " 52% 3484/6727 [00:04<00:04, 806.49it/s][23:41:15] WARNING: not removing hydrogen atom without neighbors\n",
      " 53% 3566/6727 [00:04<00:04, 769.83it/s][23:41:16] WARNING: not removing hydrogen atom without neighbors\n",
      " 67% 4500/6727 [00:05<00:03, 708.52it/s][23:41:17] WARNING: not removing hydrogen atom without neighbors\n",
      " 68% 4572/6727 [00:05<00:03, 703.11it/s][23:41:17] WARNING: not removing hydrogen atom without neighbors\n",
      " 74% 4966/6727 [00:06<00:02, 745.96it/s][23:41:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:41:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:41:17] WARNING: not removing hydrogen atom without neighbors\n",
      " 83% 5550/6727 [00:06<00:01, 677.84it/s][23:41:18] WARNING: not removing hydrogen atom without neighbors\n",
      " 89% 5999/6727 [00:07<00:01, 723.71it/s][23:41:19] WARNING: not removing hydrogen atom without neighbors\n",
      " 90% 6072/6727 [00:07<00:00, 711.03it/s][23:41:19] WARNING: not removing hydrogen atom without neighbors\n",
      " 93% 6235/6727 [00:07<00:00, 741.11it/s][23:41:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:41:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:41:19] WARNING: not removing hydrogen atom without neighbors\n",
      " 96% 6469/6727 [00:08<00:00, 756.20it/s][23:41:20] WARNING: not removing hydrogen atom without neighbors\n",
      "100% 6727/6727 [00:08<00:00, 790.35it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "/content/PretrainDPI\n"
     ]
    }
   ],
   "source": [
    "%cd PretrainDPI/data\n",
    "!python preprocess.py --dataset human --n_split 10 --pretrained transformer12\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXKvdGpuyMZk"
   },
   "source": [
    "We use a pretrained model from Rives et al. (BioRxiv 622803; doi:https://doi.org/10.1101/622803). The model is available in the GitHub repository (github.com/facebookresearch/esm). If you do not have the model, the `preprocess.py` code automatically downloads it.\n",
    "\n",
    "We support two training codes, `main_nn.py` and `main_dropout.py`. The latter file uses Bayesian training with MC-dropout method. We adopt concrete dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ovan8NL2yOzF",
    "outputId": "02948e10-055c-45eb-b55e-28555b8c2f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2696, 0: 2688})\n",
      "Counter({1: 337, 0: 336})\n",
      "Counter({1: 336, 0: 334})\n",
      "Time: 3.22, Epoch: 1, Train Loss: 0.5719, Val Loss: 0.4750, Val Score: 0.8476, Best Score: 0.0000\n",
      "Time: 3.20, Epoch: 2, Train Loss: 0.4188, Val Loss: 0.3806, Val Score: 0.9101, Best Score: 0.8476\n",
      "Time: 3.25, Epoch: 3, Train Loss: 0.3949, Val Loss: 0.3681, Val Score: 0.9193, Best Score: 0.9101\n",
      "Time: 3.23, Epoch: 4, Train Loss: 0.3711, Val Loss: 0.3875, Val Score: 0.9208, Best Score: 0.9193\n",
      "Time: 3.22, Epoch: 5, Train Loss: 0.3505, Val Loss: 0.3060, Val Score: 0.9413, Best Score: 0.9208\n",
      "Time: 3.15, Epoch: 6, Train Loss: 0.3451, Val Loss: 0.3230, Val Score: 0.9390, Best Score: 0.9413\n",
      "Time: 3.14, Epoch: 7, Train Loss: 0.3259, Val Loss: 0.2929, Val Score: 0.9488, Best Score: 0.9413\n",
      "Time: 3.17, Epoch: 8, Train Loss: 0.3122, Val Loss: 0.2888, Val Score: 0.9482, Best Score: 0.9488\n",
      "Time: 3.18, Epoch: 9, Train Loss: 0.3085, Val Loss: 0.2769, Val Score: 0.9538, Best Score: 0.9488\n",
      "Time: 3.20, Epoch: 10, Train Loss: 0.2879, Val Loss: 0.2882, Val Score: 0.9548, Best Score: 0.9538\n",
      "Time: 3.23, Epoch: 11, Train Loss: 0.2837, Val Loss: 0.2901, Val Score: 0.9499, Best Score: 0.9548\n",
      "Time: 3.24, Epoch: 12, Train Loss: 0.2734, Val Loss: 0.2740, Val Score: 0.9536, Best Score: 0.9548\n",
      "Time: 3.20, Epoch: 13, Train Loss: 0.2685, Val Loss: 0.2990, Val Score: 0.9500, Best Score: 0.9548\n",
      "Time: 3.17, Epoch: 14, Train Loss: 0.2635, Val Loss: 0.2872, Val Score: 0.9601, Best Score: 0.9548\n",
      "Time: 3.21, Epoch: 15, Train Loss: 0.2451, Val Loss: 0.2498, Val Score: 0.9647, Best Score: 0.9601\n",
      "Time: 3.16, Epoch: 16, Train Loss: 0.2459, Val Loss: 0.2325, Val Score: 0.9696, Best Score: 0.9647\n",
      "Time: 3.23, Epoch: 17, Train Loss: 0.2379, Val Loss: 0.2644, Val Score: 0.9613, Best Score: 0.9696\n",
      "Time: 3.22, Epoch: 18, Train Loss: 0.2246, Val Loss: 0.2358, Val Score: 0.9670, Best Score: 0.9696\n",
      "Time: 3.17, Epoch: 19, Train Loss: 0.2116, Val Loss: 0.2485, Val Score: 0.9680, Best Score: 0.9696\n",
      "Time: 3.17, Epoch: 20, Train Loss: 0.2083, Val Loss: 0.2688, Val Score: 0.9668, Best Score: 0.9696\n",
      "Time: 3.19, Epoch: 21, Train Loss: 0.1945, Val Loss: 0.2452, Val Score: 0.9708, Best Score: 0.9696\n",
      "Time: 3.22, Epoch: 22, Train Loss: 0.1824, Val Loss: 0.2353, Val Score: 0.9728, Best Score: 0.9708\n",
      "Time: 3.17, Epoch: 23, Train Loss: 0.1725, Val Loss: 0.2187, Val Score: 0.9756, Best Score: 0.9728\n",
      "Time: 3.22, Epoch: 24, Train Loss: 0.1553, Val Loss: 0.2175, Val Score: 0.9748, Best Score: 0.9756\n",
      "Time: 3.18, Epoch: 25, Train Loss: 0.1472, Val Loss: 0.2307, Val Score: 0.9766, Best Score: 0.9756\n",
      "Time: 3.20, Epoch: 26, Train Loss: 0.1385, Val Loss: 0.2493, Val Score: 0.9759, Best Score: 0.9766\n",
      "Time: 3.17, Epoch: 27, Train Loss: 0.1313, Val Loss: 0.2239, Val Score: 0.9763, Best Score: 0.9766\n",
      "Time: 3.17, Epoch: 28, Train Loss: 0.1127, Val Loss: 0.2741, Val Score: 0.9732, Best Score: 0.9766\n",
      "Time: 3.22, Epoch: 29, Train Loss: 0.1139, Val Loss: 0.2742, Val Score: 0.9771, Best Score: 0.9766\n",
      "Time: 3.23, Epoch: 30, Train Loss: 0.1028, Val Loss: 0.2714, Val Score: 0.9778, Best Score: 0.9771\n",
      "Time: 3.22, Epoch: 31, Train Loss: 0.1052, Val Loss: 0.2422, Val Score: 0.9735, Best Score: 0.9778\n",
      "Time: 3.27, Epoch: 32, Train Loss: 0.0964, Val Loss: 0.3126, Val Score: 0.9725, Best Score: 0.9778\n",
      "Time: 3.20, Epoch: 33, Train Loss: 0.0835, Val Loss: 0.2427, Val Score: 0.9804, Best Score: 0.9778\n",
      "Time: 3.24, Epoch: 34, Train Loss: 0.0811, Val Loss: 0.3504, Val Score: 0.9798, Best Score: 0.9804\n",
      "Time: 3.19, Epoch: 35, Train Loss: 0.0824, Val Loss: 0.3626, Val Score: 0.9760, Best Score: 0.9804\n",
      "Time: 3.22, Epoch: 36, Train Loss: 0.0811, Val Loss: 0.2421, Val Score: 0.9836, Best Score: 0.9804\n",
      "Time: 3.17, Epoch: 37, Train Loss: 0.0666, Val Loss: 0.2566, Val Score: 0.9801, Best Score: 0.9836\n",
      "Time: 3.18, Epoch: 38, Train Loss: 0.0695, Val Loss: 0.2692, Val Score: 0.9780, Best Score: 0.9836\n",
      "Time: 3.19, Epoch: 39, Train Loss: 0.0591, Val Loss: 0.2738, Val Score: 0.9822, Best Score: 0.9836\n",
      "Time: 3.21, Epoch: 40, Train Loss: 0.0556, Val Loss: 0.2826, Val Score: 0.9798, Best Score: 0.9836\n",
      "Time: 3.27, Epoch: 41, Train Loss: 0.0604, Val Loss: 0.2926, Val Score: 0.9819, Best Score: 0.9836\n",
      "Time: 3.26, Epoch: 42, Train Loss: 0.0574, Val Loss: 0.2780, Val Score: 0.9812, Best Score: 0.9836\n",
      "Time: 3.27, Epoch: 43, Train Loss: 0.0452, Val Loss: 0.3437, Val Score: 0.9796, Best Score: 0.9836\n",
      "Time: 3.19, Epoch: 44, Train Loss: 0.0453, Val Loss: 0.3680, Val Score: 0.9778, Best Score: 0.9836\n",
      "Time: 3.25, Epoch: 45, Train Loss: 0.0532, Val Loss: 0.3803, Val Score: 0.9774, Best Score: 0.9836\n",
      "Time: 3.21, Epoch: 46, Train Loss: 0.0513, Val Loss: 0.2760, Val Score: 0.9803, Best Score: 0.9836\n",
      "Epoch    47: reducing learning rate of group 0 to 9.5000e-04.\n",
      "Time: 3.23, Epoch: 47, Train Loss: 0.0478, Val Loss: 0.2467, Val Score: 0.9818, Best Score: 0.9836\n",
      "Time: 3.26, Epoch: 48, Train Loss: 0.0452, Val Loss: 0.2875, Val Score: 0.9873, Best Score: 0.9836\n",
      "Time: 3.21, Epoch: 49, Train Loss: 0.0346, Val Loss: 0.3379, Val Score: 0.9819, Best Score: 0.9873\n",
      "Time: 3.19, Epoch: 50, Train Loss: 0.0441, Val Loss: 0.2892, Val Score: 0.9847, Best Score: 0.9873\n",
      "Time: 3.19, Epoch: 51, Train Loss: 0.0319, Val Loss: 0.3098, Val Score: 0.9836, Best Score: 0.9873\n",
      "Time: 3.27, Epoch: 52, Train Loss: 0.0215, Val Loss: 0.4155, Val Score: 0.9795, Best Score: 0.9873\n",
      "Time: 3.24, Epoch: 53, Train Loss: 0.0270, Val Loss: 0.4209, Val Score: 0.9796, Best Score: 0.9873\n",
      "Time: 3.20, Epoch: 54, Train Loss: 0.0370, Val Loss: 0.2699, Val Score: 0.9834, Best Score: 0.9873\n",
      "Time: 3.26, Epoch: 55, Train Loss: 0.0383, Val Loss: 0.2242, Val Score: 0.9867, Best Score: 0.9873\n",
      "Time: 3.24, Epoch: 56, Train Loss: 0.0211, Val Loss: 0.3279, Val Score: 0.9833, Best Score: 0.9873\n",
      "Time: 3.23, Epoch: 57, Train Loss: 0.0245, Val Loss: 0.2997, Val Score: 0.9855, Best Score: 0.9873\n",
      "Time: 3.19, Epoch: 58, Train Loss: 0.0231, Val Loss: 0.3980, Val Score: 0.9805, Best Score: 0.9873\n",
      "Epoch    59: reducing learning rate of group 0 to 9.0250e-04.\n",
      "Time: 3.19, Epoch: 59, Train Loss: 0.0142, Val Loss: 0.3571, Val Score: 0.9862, Best Score: 0.9873\n",
      "Time: 3.24, Epoch: 60, Train Loss: 0.0323, Val Loss: 0.2223, Val Score: 0.9853, Best Score: 0.9873\n",
      "Time: 3.18, Epoch: 61, Train Loss: 0.0270, Val Loss: 0.2765, Val Score: 0.9817, Best Score: 0.9873\n",
      "Time: 3.26, Epoch: 62, Train Loss: 0.0243, Val Loss: 0.1964, Val Score: 0.9887, Best Score: 0.9873\n",
      "Time: 3.28, Epoch: 63, Train Loss: 0.0191, Val Loss: 0.2957, Val Score: 0.9854, Best Score: 0.9887\n",
      "Time: 3.20, Epoch: 64, Train Loss: 0.0164, Val Loss: 0.2994, Val Score: 0.9867, Best Score: 0.9887\n",
      "Time: 3.25, Epoch: 65, Train Loss: 0.0164, Val Loss: 0.4227, Val Score: 0.9827, Best Score: 0.9887\n",
      "Time: 3.18, Epoch: 66, Train Loss: 0.0264, Val Loss: 0.2375, Val Score: 0.9870, Best Score: 0.9887\n",
      "Time: 3.27, Epoch: 67, Train Loss: 0.0105, Val Loss: 0.4591, Val Score: 0.9850, Best Score: 0.9887\n",
      "Time: 3.24, Epoch: 68, Train Loss: 0.0169, Val Loss: 0.3347, Val Score: 0.9843, Best Score: 0.9887\n",
      "Time: 3.18, Epoch: 69, Train Loss: 0.0150, Val Loss: 0.3396, Val Score: 0.9838, Best Score: 0.9887\n",
      "Time: 3.23, Epoch: 70, Train Loss: 0.0190, Val Loss: 0.3064, Val Score: 0.9854, Best Score: 0.9887\n",
      "Time: 3.26, Epoch: 71, Train Loss: 0.0180, Val Loss: 0.3156, Val Score: 0.9844, Best Score: 0.9887\n",
      "Time: 3.32, Epoch: 72, Train Loss: 0.0211, Val Loss: 0.2767, Val Score: 0.9853, Best Score: 0.9887\n",
      "Epoch    73: reducing learning rate of group 0 to 8.5737e-04.\n",
      "Time: 3.31, Epoch: 73, Train Loss: 0.0212, Val Loss: 0.2651, Val Score: 0.9841, Best Score: 0.9887\n",
      "Time: 3.21, Epoch: 74, Train Loss: 0.0136, Val Loss: 0.3625, Val Score: 0.9854, Best Score: 0.9887\n",
      "Time: 3.25, Epoch: 75, Train Loss: 0.0157, Val Loss: 0.3437, Val Score: 0.9832, Best Score: 0.9887\n",
      "Time: 3.22, Epoch: 76, Train Loss: 0.0218, Val Loss: 0.3417, Val Score: 0.9848, Best Score: 0.9887\n",
      "Time: 3.22, Epoch: 77, Train Loss: 0.0191, Val Loss: 0.3436, Val Score: 0.9851, Best Score: 0.9887\n",
      "Time: 3.26, Epoch: 78, Train Loss: 0.0180, Val Loss: 0.4364, Val Score: 0.9768, Best Score: 0.9887\n",
      "Time: 3.24, Epoch: 79, Train Loss: 0.0209, Val Loss: 0.3228, Val Score: 0.9869, Best Score: 0.9887\n",
      "Time: 3.24, Epoch: 80, Train Loss: 0.0172, Val Loss: 0.3432, Val Score: 0.9867, Best Score: 0.9887\n",
      "Time: 3.18, Epoch: 81, Train Loss: 0.0148, Val Loss: 0.3259, Val Score: 0.9858, Best Score: 0.9887\n",
      "Time: 3.24, Epoch: 82, Train Loss: 0.0099, Val Loss: 0.3590, Val Score: 0.9844, Best Score: 0.9887\n",
      "Time: 3.23, Epoch: 83, Train Loss: 0.0073, Val Loss: 0.4708, Val Score: 0.9811, Best Score: 0.9887\n",
      "Epoch    84: reducing learning rate of group 0 to 8.1451e-04.\n",
      "Time: 3.24, Epoch: 84, Train Loss: 0.0255, Val Loss: 0.3270, Val Score: 0.9845, Best Score: 0.9887\n",
      "Time: 3.17, Epoch: 85, Train Loss: 0.0084, Val Loss: 0.4250, Val Score: 0.9813, Best Score: 0.9887\n",
      "Time: 3.24, Epoch: 86, Train Loss: 0.0156, Val Loss: 0.3694, Val Score: 0.9830, Best Score: 0.9887\n",
      "Time: 3.20, Epoch: 87, Train Loss: 0.0118, Val Loss: 0.3820, Val Score: 0.9812, Best Score: 0.9887\n",
      "Time: 3.25, Epoch: 88, Train Loss: 0.0190, Val Loss: 0.3835, Val Score: 0.9785, Best Score: 0.9887\n",
      "Time: 3.22, Epoch: 89, Train Loss: 0.0147, Val Loss: 0.3508, Val Score: 0.9831, Best Score: 0.9887\n",
      "Time: 3.25, Epoch: 90, Train Loss: 0.0129, Val Loss: 0.3416, Val Score: 0.9829, Best Score: 0.9887\n",
      "Time: 3.25, Epoch: 91, Train Loss: 0.0234, Val Loss: 0.2851, Val Score: 0.9865, Best Score: 0.9887\n",
      "Time: 3.31, Epoch: 92, Train Loss: 0.0094, Val Loss: 0.5609, Val Score: 0.9805, Best Score: 0.9887\n",
      "Time: 3.32, Epoch: 93, Train Loss: 0.0142, Val Loss: 0.3431, Val Score: 0.9832, Best Score: 0.9887\n",
      "Time: 3.31, Epoch: 94, Train Loss: 0.0227, Val Loss: 0.3055, Val Score: 0.9811, Best Score: 0.9887\n",
      "Epoch    95: reducing learning rate of group 0 to 7.7378e-04.\n",
      "Time: 3.24, Epoch: 95, Train Loss: 0.0131, Val Loss: 0.3696, Val Score: 0.9848, Best Score: 0.9887\n",
      "Time: 3.21, Epoch: 96, Train Loss: 0.0109, Val Loss: 0.2342, Val Score: 0.9904, Best Score: 0.9887\n",
      "Time: 3.21, Epoch: 97, Train Loss: 0.0088, Val Loss: 0.2888, Val Score: 0.9878, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 98, Train Loss: 0.0099, Val Loss: 0.3166, Val Score: 0.9873, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 99, Train Loss: 0.0176, Val Loss: 0.2362, Val Score: 0.9879, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 100, Train Loss: 0.0049, Val Loss: 0.2948, Val Score: 0.9900, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 101, Train Loss: 0.0032, Val Loss: 0.3410, Val Score: 0.9884, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 102, Train Loss: 0.0093, Val Loss: 0.4851, Val Score: 0.9846, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 103, Train Loss: 0.0119, Val Loss: 0.3312, Val Score: 0.9867, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 104, Train Loss: 0.0026, Val Loss: 0.4423, Val Score: 0.9851, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 105, Train Loss: 0.0073, Val Loss: 0.4084, Val Score: 0.9822, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 106, Train Loss: 0.0048, Val Loss: 0.4428, Val Score: 0.9874, Best Score: 0.9904\n",
      "Epoch   107: reducing learning rate of group 0 to 7.3509e-04.\n",
      "Time: 3.23, Epoch: 107, Train Loss: 0.0272, Val Loss: 0.2993, Val Score: 0.9878, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 108, Train Loss: 0.0057, Val Loss: 0.4722, Val Score: 0.9834, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 109, Train Loss: 0.0126, Val Loss: 0.3424, Val Score: 0.9861, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 110, Train Loss: 0.0134, Val Loss: 0.2727, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 111, Train Loss: 0.0147, Val Loss: 0.3265, Val Score: 0.9878, Best Score: 0.9904\n",
      "Time: 3.28, Epoch: 112, Train Loss: 0.0092, Val Loss: 0.3499, Val Score: 0.9867, Best Score: 0.9904\n",
      "Time: 3.29, Epoch: 113, Train Loss: 0.0042, Val Loss: 0.3730, Val Score: 0.9865, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 114, Train Loss: 0.0058, Val Loss: 0.4100, Val Score: 0.9874, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 115, Train Loss: 0.0088, Val Loss: 0.3128, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.17, Epoch: 116, Train Loss: 0.0074, Val Loss: 0.4064, Val Score: 0.9836, Best Score: 0.9904\n",
      "Time: 3.14, Epoch: 117, Train Loss: 0.0077, Val Loss: 0.2767, Val Score: 0.9890, Best Score: 0.9904\n",
      "Epoch   118: reducing learning rate of group 0 to 6.9834e-04.\n",
      "Time: 3.17, Epoch: 118, Train Loss: 0.0060, Val Loss: 0.4527, Val Score: 0.9834, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 119, Train Loss: 0.0114, Val Loss: 0.4400, Val Score: 0.9845, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 120, Train Loss: 0.0123, Val Loss: 0.2909, Val Score: 0.9876, Best Score: 0.9904\n",
      "Time: 3.13, Epoch: 121, Train Loss: 0.0049, Val Loss: 0.3452, Val Score: 0.9859, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 122, Train Loss: 0.0049, Val Loss: 0.3116, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 123, Train Loss: 0.0070, Val Loss: 0.3269, Val Score: 0.9868, Best Score: 0.9904\n",
      "Time: 3.17, Epoch: 124, Train Loss: 0.0040, Val Loss: 0.3798, Val Score: 0.9859, Best Score: 0.9904\n",
      "Time: 3.16, Epoch: 125, Train Loss: 0.0110, Val Loss: 0.5072, Val Score: 0.9812, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 126, Train Loss: 0.0113, Val Loss: 0.2923, Val Score: 0.9872, Best Score: 0.9904\n",
      "Time: 3.16, Epoch: 127, Train Loss: 0.0058, Val Loss: 0.3442, Val Score: 0.9859, Best Score: 0.9904\n",
      "Time: 3.14, Epoch: 128, Train Loss: 0.0022, Val Loss: 0.3346, Val Score: 0.9876, Best Score: 0.9904\n",
      "Epoch   129: reducing learning rate of group 0 to 6.6342e-04.\n",
      "Time: 3.21, Epoch: 129, Train Loss: 0.0053, Val Loss: 0.3899, Val Score: 0.9866, Best Score: 0.9904\n",
      "Time: 3.14, Epoch: 130, Train Loss: 0.0070, Val Loss: 0.4137, Val Score: 0.9860, Best Score: 0.9904\n",
      "Time: 3.09, Epoch: 131, Train Loss: 0.0109, Val Loss: 0.2937, Val Score: 0.9871, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 132, Train Loss: 0.0039, Val Loss: 0.4144, Val Score: 0.9865, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 133, Train Loss: 0.0055, Val Loss: 0.2840, Val Score: 0.9879, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 134, Train Loss: 0.0050, Val Loss: 0.3419, Val Score: 0.9879, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 135, Train Loss: 0.0007, Val Loss: 0.4562, Val Score: 0.9862, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 136, Train Loss: 0.0013, Val Loss: 0.4873, Val Score: 0.9850, Best Score: 0.9904\n",
      "Time: 3.16, Epoch: 137, Train Loss: 0.0136, Val Loss: 0.4024, Val Score: 0.9849, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 138, Train Loss: 0.0118, Val Loss: 0.3075, Val Score: 0.9886, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 139, Train Loss: 0.0040, Val Loss: 0.3765, Val Score: 0.9857, Best Score: 0.9904\n",
      "Epoch   140: reducing learning rate of group 0 to 6.3025e-04.\n",
      "Time: 3.18, Epoch: 140, Train Loss: 0.0126, Val Loss: 0.3569, Val Score: 0.9836, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 141, Train Loss: 0.0053, Val Loss: 0.4159, Val Score: 0.9867, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 142, Train Loss: 0.0048, Val Loss: 0.7512, Val Score: 0.9777, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 143, Train Loss: 0.0072, Val Loss: 0.3773, Val Score: 0.9852, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 144, Train Loss: 0.0039, Val Loss: 0.4160, Val Score: 0.9858, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 145, Train Loss: 0.0037, Val Loss: 0.4054, Val Score: 0.9846, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 146, Train Loss: 0.0124, Val Loss: 0.3015, Val Score: 0.9858, Best Score: 0.9904\n",
      "Time: 3.16, Epoch: 147, Train Loss: 0.0054, Val Loss: 0.3798, Val Score: 0.9856, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 148, Train Loss: 0.0035, Val Loss: 0.4648, Val Score: 0.9855, Best Score: 0.9904\n",
      "Time: 3.15, Epoch: 149, Train Loss: 0.0077, Val Loss: 0.3786, Val Score: 0.9854, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 150, Train Loss: 0.0029, Val Loss: 0.3434, Val Score: 0.9882, Best Score: 0.9904\n",
      "Epoch   151: reducing learning rate of group 0 to 5.9874e-04.\n",
      "Time: 3.17, Epoch: 151, Train Loss: 0.0091, Val Loss: 0.3773, Val Score: 0.9850, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 152, Train Loss: 0.0015, Val Loss: 0.5057, Val Score: 0.9823, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 153, Train Loss: 0.0075, Val Loss: 0.5302, Val Score: 0.9837, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 154, Train Loss: 0.0042, Val Loss: 0.3374, Val Score: 0.9872, Best Score: 0.9904\n",
      "Time: 3.15, Epoch: 155, Train Loss: 0.0062, Val Loss: 0.4208, Val Score: 0.9849, Best Score: 0.9904\n",
      "Time: 3.17, Epoch: 156, Train Loss: 0.0054, Val Loss: 0.4116, Val Score: 0.9846, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 157, Train Loss: 0.0030, Val Loss: 0.4306, Val Score: 0.9858, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 158, Train Loss: 0.0023, Val Loss: 0.6109, Val Score: 0.9812, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 159, Train Loss: 0.0121, Val Loss: 0.4824, Val Score: 0.9850, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 160, Train Loss: 0.0072, Val Loss: 0.5609, Val Score: 0.9823, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 161, Train Loss: 0.0105, Val Loss: 0.4166, Val Score: 0.9836, Best Score: 0.9904\n",
      "Epoch   162: reducing learning rate of group 0 to 5.6880e-04.\n",
      "Time: 3.16, Epoch: 162, Train Loss: 0.0045, Val Loss: 0.4001, Val Score: 0.9841, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 163, Train Loss: 0.0043, Val Loss: 0.4360, Val Score: 0.9849, Best Score: 0.9904\n",
      "Time: 3.14, Epoch: 164, Train Loss: 0.0037, Val Loss: 0.3894, Val Score: 0.9876, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 165, Train Loss: 0.0064, Val Loss: 0.5163, Val Score: 0.9837, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 166, Train Loss: 0.0049, Val Loss: 0.4706, Val Score: 0.9835, Best Score: 0.9904\n",
      "Time: 3.30, Epoch: 167, Train Loss: 0.0040, Val Loss: 0.4878, Val Score: 0.9854, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 168, Train Loss: 0.0033, Val Loss: 0.5016, Val Score: 0.9846, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 169, Train Loss: 0.0021, Val Loss: 0.3734, Val Score: 0.9871, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 170, Train Loss: 0.0055, Val Loss: 0.3893, Val Score: 0.9870, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 171, Train Loss: 0.0036, Val Loss: 0.3800, Val Score: 0.9869, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 172, Train Loss: 0.0012, Val Loss: 0.3498, Val Score: 0.9879, Best Score: 0.9904\n",
      "Epoch   173: reducing learning rate of group 0 to 5.4036e-04.\n",
      "Time: 3.20, Epoch: 173, Train Loss: 0.0048, Val Loss: 0.4102, Val Score: 0.9848, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 174, Train Loss: 0.0006, Val Loss: 0.3869, Val Score: 0.9890, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 175, Train Loss: 0.0051, Val Loss: 0.4384, Val Score: 0.9869, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 176, Train Loss: 0.0015, Val Loss: 0.4580, Val Score: 0.9854, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 177, Train Loss: 0.0005, Val Loss: 0.4931, Val Score: 0.9859, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 178, Train Loss: 0.0011, Val Loss: 0.4546, Val Score: 0.9881, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 179, Train Loss: 0.0033, Val Loss: 0.4500, Val Score: 0.9846, Best Score: 0.9904\n",
      "Time: 3.17, Epoch: 180, Train Loss: 0.0026, Val Loss: 0.4545, Val Score: 0.9854, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 181, Train Loss: 0.0002, Val Loss: 0.4700, Val Score: 0.9853, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 182, Train Loss: 0.0010, Val Loss: 0.5775, Val Score: 0.9848, Best Score: 0.9904\n",
      "Time: 3.31, Epoch: 183, Train Loss: 0.0018, Val Loss: 0.3808, Val Score: 0.9880, Best Score: 0.9904\n",
      "Epoch   184: reducing learning rate of group 0 to 5.1334e-04.\n",
      "Time: 3.30, Epoch: 184, Train Loss: 0.0084, Val Loss: 0.4475, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 185, Train Loss: 0.0124, Val Loss: 0.3851, Val Score: 0.9865, Best Score: 0.9904\n",
      "Time: 3.31, Epoch: 186, Train Loss: 0.0016, Val Loss: 0.4992, Val Score: 0.9822, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 187, Train Loss: 0.0078, Val Loss: 0.3784, Val Score: 0.9869, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 188, Train Loss: 0.0053, Val Loss: 0.3886, Val Score: 0.9872, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 189, Train Loss: 0.0052, Val Loss: 0.3825, Val Score: 0.9876, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 190, Train Loss: 0.0040, Val Loss: 0.3380, Val Score: 0.9884, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 191, Train Loss: 0.0021, Val Loss: 0.3908, Val Score: 0.9861, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 192, Train Loss: 0.0062, Val Loss: 0.4428, Val Score: 0.9857, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 193, Train Loss: 0.0005, Val Loss: 0.5515, Val Score: 0.9832, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 194, Train Loss: 0.0011, Val Loss: 0.4940, Val Score: 0.9845, Best Score: 0.9904\n",
      "Epoch   195: reducing learning rate of group 0 to 4.8767e-04.\n",
      "Time: 3.23, Epoch: 195, Train Loss: 0.0049, Val Loss: 0.4792, Val Score: 0.9829, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 196, Train Loss: 0.0013, Val Loss: 0.5626, Val Score: 0.9835, Best Score: 0.9904\n",
      "Time: 3.29, Epoch: 197, Train Loss: 0.0028, Val Loss: 0.4909, Val Score: 0.9839, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 198, Train Loss: 0.0021, Val Loss: 0.4521, Val Score: 0.9869, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 199, Train Loss: 0.0047, Val Loss: 0.3803, Val Score: 0.9861, Best Score: 0.9904\n",
      "Time: 3.17, Epoch: 200, Train Loss: 0.0020, Val Loss: 0.3677, Val Score: 0.9863, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 201, Train Loss: 0.0075, Val Loss: 0.3507, Val Score: 0.9865, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 202, Train Loss: 0.0012, Val Loss: 0.4518, Val Score: 0.9860, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 203, Train Loss: 0.0036, Val Loss: 0.4601, Val Score: 0.9874, Best Score: 0.9904\n",
      "Time: 3.28, Epoch: 204, Train Loss: 0.0041, Val Loss: 0.3872, Val Score: 0.9881, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 205, Train Loss: 0.0015, Val Loss: 0.4322, Val Score: 0.9869, Best Score: 0.9904\n",
      "Epoch   206: reducing learning rate of group 0 to 4.6329e-04.\n",
      "Time: 3.27, Epoch: 206, Train Loss: 0.0007, Val Loss: 0.4714, Val Score: 0.9871, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 207, Train Loss: 0.0003, Val Loss: 0.4735, Val Score: 0.9862, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 208, Train Loss: 0.0007, Val Loss: 0.5988, Val Score: 0.9826, Best Score: 0.9904\n",
      "Time: 3.29, Epoch: 209, Train Loss: 0.0004, Val Loss: 0.6413, Val Score: 0.9845, Best Score: 0.9904\n",
      "Time: 3.18, Epoch: 210, Train Loss: 0.0068, Val Loss: 0.5766, Val Score: 0.9815, Best Score: 0.9904\n",
      "Time: 3.20, Epoch: 211, Train Loss: 0.0066, Val Loss: 0.3061, Val Score: 0.9897, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 212, Train Loss: 0.0013, Val Loss: 0.4159, Val Score: 0.9889, Best Score: 0.9904\n",
      "Time: 3.28, Epoch: 213, Train Loss: 0.0006, Val Loss: 0.4586, Val Score: 0.9865, Best Score: 0.9904\n",
      "Time: 3.28, Epoch: 214, Train Loss: 0.0002, Val Loss: 0.4814, Val Score: 0.9864, Best Score: 0.9904\n",
      "Time: 3.35, Epoch: 215, Train Loss: 0.0035, Val Loss: 0.4737, Val Score: 0.9858, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 216, Train Loss: 0.0025, Val Loss: 0.3479, Val Score: 0.9892, Best Score: 0.9904\n",
      "Epoch   217: reducing learning rate of group 0 to 4.4013e-04.\n",
      "Time: 3.25, Epoch: 217, Train Loss: 0.0047, Val Loss: 0.4559, Val Score: 0.9864, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 218, Train Loss: 0.0038, Val Loss: 0.4476, Val Score: 0.9863, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 219, Train Loss: 0.0022, Val Loss: 0.5113, Val Score: 0.9842, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 220, Train Loss: 0.0007, Val Loss: 0.4850, Val Score: 0.9840, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 221, Train Loss: 0.0057, Val Loss: 0.6729, Val Score: 0.9791, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 222, Train Loss: 0.0008, Val Loss: 0.7034, Val Score: 0.9776, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 223, Train Loss: 0.0114, Val Loss: 0.3986, Val Score: 0.9876, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 224, Train Loss: 0.0015, Val Loss: 0.4766, Val Score: 0.9859, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 225, Train Loss: 0.0024, Val Loss: 0.4589, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 226, Train Loss: 0.0011, Val Loss: 0.4074, Val Score: 0.9876, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 227, Train Loss: 0.0032, Val Loss: 0.4796, Val Score: 0.9846, Best Score: 0.9904\n",
      "Epoch   228: reducing learning rate of group 0 to 4.1812e-04.\n",
      "Time: 3.24, Epoch: 228, Train Loss: 0.0019, Val Loss: 0.4873, Val Score: 0.9860, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 229, Train Loss: 0.0040, Val Loss: 0.5482, Val Score: 0.9847, Best Score: 0.9904\n",
      "Time: 3.32, Epoch: 230, Train Loss: 0.0011, Val Loss: 0.4864, Val Score: 0.9842, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 231, Train Loss: 0.0003, Val Loss: 0.4823, Val Score: 0.9863, Best Score: 0.9904\n",
      "Time: 3.22, Epoch: 232, Train Loss: 0.0002, Val Loss: 0.4732, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 233, Train Loss: 0.0007, Val Loss: 0.5867, Val Score: 0.9848, Best Score: 0.9904\n",
      "Time: 3.31, Epoch: 234, Train Loss: 0.0032, Val Loss: 0.4779, Val Score: 0.9864, Best Score: 0.9904\n",
      "Time: 3.32, Epoch: 235, Train Loss: 0.0008, Val Loss: 0.5434, Val Score: 0.9868, Best Score: 0.9904\n",
      "Time: 3.23, Epoch: 236, Train Loss: 0.0014, Val Loss: 0.4376, Val Score: 0.9874, Best Score: 0.9904\n",
      "Time: 3.30, Epoch: 237, Train Loss: 0.0006, Val Loss: 0.7058, Val Score: 0.9802, Best Score: 0.9904\n",
      "Time: 3.28, Epoch: 238, Train Loss: 0.0003, Val Loss: 0.7695, Val Score: 0.9800, Best Score: 0.9904\n",
      "Epoch   239: reducing learning rate of group 0 to 3.9721e-04.\n",
      "Time: 3.28, Epoch: 239, Train Loss: 0.0001, Val Loss: 0.5729, Val Score: 0.9863, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 240, Train Loss: 0.0022, Val Loss: 0.5675, Val Score: 0.9860, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 241, Train Loss: 0.0073, Val Loss: 0.3987, Val Score: 0.9877, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 242, Train Loss: 0.0016, Val Loss: 0.4500, Val Score: 0.9857, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 243, Train Loss: 0.0047, Val Loss: 0.4529, Val Score: 0.9851, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 244, Train Loss: 0.0043, Val Loss: 0.4336, Val Score: 0.9845, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 245, Train Loss: 0.0005, Val Loss: 0.4477, Val Score: 0.9888, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 246, Train Loss: 0.0001, Val Loss: 0.5855, Val Score: 0.9812, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 247, Train Loss: 0.0035, Val Loss: 0.5206, Val Score: 0.9829, Best Score: 0.9904\n",
      "Time: 3.21, Epoch: 248, Train Loss: 0.0013, Val Loss: 0.7538, Val Score: 0.9756, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 249, Train Loss: 0.0115, Val Loss: 0.6191, Val Score: 0.9802, Best Score: 0.9904\n",
      "Epoch   250: reducing learning rate of group 0 to 3.7735e-04.\n",
      "Time: 3.26, Epoch: 250, Train Loss: 0.0036, Val Loss: 0.5160, Val Score: 0.9844, Best Score: 0.9904\n",
      "Time: 3.19, Epoch: 251, Train Loss: 0.0006, Val Loss: 0.5595, Val Score: 0.9835, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 252, Train Loss: 0.0002, Val Loss: 0.6424, Val Score: 0.9824, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 253, Train Loss: 0.0034, Val Loss: 0.5257, Val Score: 0.9841, Best Score: 0.9904\n",
      "Time: 3.27, Epoch: 254, Train Loss: 0.0030, Val Loss: 0.5521, Val Score: 0.9810, Best Score: 0.9904\n",
      "Time: 3.31, Epoch: 255, Train Loss: 0.0005, Val Loss: 0.4985, Val Score: 0.9846, Best Score: 0.9904\n",
      "Time: 3.29, Epoch: 256, Train Loss: 0.0021, Val Loss: 0.4641, Val Score: 0.9845, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 257, Train Loss: 0.0008, Val Loss: 0.5155, Val Score: 0.9847, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 258, Train Loss: 0.0003, Val Loss: 0.5867, Val Score: 0.9853, Best Score: 0.9904\n",
      "Time: 3.24, Epoch: 259, Train Loss: 0.0000, Val Loss: 0.6191, Val Score: 0.9828, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 260, Train Loss: 0.0057, Val Loss: 0.4345, Val Score: 0.9869, Best Score: 0.9904\n",
      "Epoch   261: reducing learning rate of group 0 to 3.5849e-04.\n",
      "Time: 3.35, Epoch: 261, Train Loss: 0.0029, Val Loss: 0.4258, Val Score: 0.9882, Best Score: 0.9904\n",
      "Time: 3.25, Epoch: 262, Train Loss: 0.0002, Val Loss: 0.3619, Val Score: 0.9913, Best Score: 0.9904\n",
      "Time: 3.26, Epoch: 263, Train Loss: 0.0011, Val Loss: 0.4667, Val Score: 0.9876, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 264, Train Loss: 0.0021, Val Loss: 0.4950, Val Score: 0.9844, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 265, Train Loss: 0.0006, Val Loss: 0.4609, Val Score: 0.9866, Best Score: 0.9913\n",
      "Time: 3.30, Epoch: 266, Train Loss: 0.0021, Val Loss: 0.3786, Val Score: 0.9885, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 267, Train Loss: 0.0017, Val Loss: 0.4314, Val Score: 0.9877, Best Score: 0.9913\n",
      "Time: 3.23, Epoch: 268, Train Loss: 0.0082, Val Loss: 0.4494, Val Score: 0.9848, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 269, Train Loss: 0.0006, Val Loss: 0.4646, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 270, Train Loss: 0.0001, Val Loss: 0.5429, Val Score: 0.9841, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 271, Train Loss: 0.0016, Val Loss: 0.4609, Val Score: 0.9871, Best Score: 0.9913\n",
      "Time: 3.22, Epoch: 272, Train Loss: 0.0002, Val Loss: 0.4845, Val Score: 0.9871, Best Score: 0.9913\n",
      "Epoch   273: reducing learning rate of group 0 to 3.4056e-04.\n",
      "Time: 3.23, Epoch: 273, Train Loss: 0.0000, Val Loss: 0.4637, Val Score: 0.9876, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 274, Train Loss: 0.0016, Val Loss: 0.5659, Val Score: 0.9869, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 275, Train Loss: 0.0034, Val Loss: 0.3676, Val Score: 0.9874, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 276, Train Loss: 0.0025, Val Loss: 0.4162, Val Score: 0.9874, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 277, Train Loss: 0.0012, Val Loss: 0.6148, Val Score: 0.9815, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 278, Train Loss: 0.0004, Val Loss: 0.6419, Val Score: 0.9834, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 279, Train Loss: 0.0003, Val Loss: 0.7234, Val Score: 0.9802, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 280, Train Loss: 0.0017, Val Loss: 0.5496, Val Score: 0.9875, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 281, Train Loss: 0.0141, Val Loss: 0.3560, Val Score: 0.9865, Best Score: 0.9913\n",
      "Time: 3.30, Epoch: 282, Train Loss: 0.0009, Val Loss: 0.3834, Val Score: 0.9896, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 283, Train Loss: 0.0006, Val Loss: 0.5255, Val Score: 0.9859, Best Score: 0.9913\n",
      "Epoch   284: reducing learning rate of group 0 to 3.2353e-04.\n",
      "Time: 3.36, Epoch: 284, Train Loss: 0.0001, Val Loss: 0.4400, Val Score: 0.9878, Best Score: 0.9913\n",
      "Time: 3.30, Epoch: 285, Train Loss: 0.0008, Val Loss: 0.4718, Val Score: 0.9862, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 286, Train Loss: 0.0003, Val Loss: 0.4909, Val Score: 0.9890, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 287, Train Loss: 0.0015, Val Loss: 0.4910, Val Score: 0.9875, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 288, Train Loss: 0.0001, Val Loss: 0.4839, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 289, Train Loss: 0.0019, Val Loss: 0.5879, Val Score: 0.9831, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 290, Train Loss: 0.0020, Val Loss: 0.4932, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 291, Train Loss: 0.0003, Val Loss: 0.5258, Val Score: 0.9853, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 292, Train Loss: 0.0013, Val Loss: 0.7808, Val Score: 0.9780, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 293, Train Loss: 0.0019, Val Loss: 0.6068, Val Score: 0.9860, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 294, Train Loss: 0.0029, Val Loss: 0.7127, Val Score: 0.9791, Best Score: 0.9913\n",
      "Epoch   295: reducing learning rate of group 0 to 3.0736e-04.\n",
      "Time: 3.38, Epoch: 295, Train Loss: 0.0013, Val Loss: 0.7218, Val Score: 0.9796, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 296, Train Loss: 0.0033, Val Loss: 0.5976, Val Score: 0.9802, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 297, Train Loss: 0.0018, Val Loss: 0.5347, Val Score: 0.9840, Best Score: 0.9913\n",
      "Time: 3.30, Epoch: 298, Train Loss: 0.0013, Val Loss: 0.4894, Val Score: 0.9865, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 299, Train Loss: 0.0026, Val Loss: 0.4280, Val Score: 0.9879, Best Score: 0.9913\n",
      "Time: 3.21, Epoch: 300, Train Loss: 0.0008, Val Loss: 0.4912, Val Score: 0.9858, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 301, Train Loss: 0.0048, Val Loss: 0.4543, Val Score: 0.9846, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 302, Train Loss: 0.0019, Val Loss: 0.5018, Val Score: 0.9847, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 303, Train Loss: 0.0002, Val Loss: 0.5323, Val Score: 0.9853, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 304, Train Loss: 0.0007, Val Loss: 0.5464, Val Score: 0.9854, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 305, Train Loss: 0.0001, Val Loss: 0.5238, Val Score: 0.9875, Best Score: 0.9913\n",
      "Epoch   306: reducing learning rate of group 0 to 2.9199e-04.\n",
      "Time: 3.30, Epoch: 306, Train Loss: 0.0009, Val Loss: 0.5400, Val Score: 0.9867, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 307, Train Loss: 0.0005, Val Loss: 0.5766, Val Score: 0.9838, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 308, Train Loss: 0.0000, Val Loss: 0.4566, Val Score: 0.9888, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 309, Train Loss: 0.0004, Val Loss: 0.5783, Val Score: 0.9863, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 310, Train Loss: 0.0000, Val Loss: 0.5918, Val Score: 0.9843, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 311, Train Loss: 0.0002, Val Loss: 0.6132, Val Score: 0.9848, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 312, Train Loss: 0.0000, Val Loss: 0.5680, Val Score: 0.9860, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 313, Train Loss: 0.0024, Val Loss: 0.6537, Val Score: 0.9826, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 314, Train Loss: 0.0022, Val Loss: 0.4659, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 315, Train Loss: 0.0001, Val Loss: 0.6632, Val Score: 0.9810, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 316, Train Loss: 0.0010, Val Loss: 0.7217, Val Score: 0.9812, Best Score: 0.9913\n",
      "Epoch   317: reducing learning rate of group 0 to 2.7739e-04.\n",
      "Time: 3.35, Epoch: 317, Train Loss: 0.0085, Val Loss: 0.4799, Val Score: 0.9870, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 318, Train Loss: 0.0005, Val Loss: 0.5660, Val Score: 0.9824, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 319, Train Loss: 0.0002, Val Loss: 0.5739, Val Score: 0.9833, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 320, Train Loss: 0.0001, Val Loss: 0.5766, Val Score: 0.9838, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 321, Train Loss: 0.0026, Val Loss: 0.5353, Val Score: 0.9852, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 322, Train Loss: 0.0000, Val Loss: 0.5218, Val Score: 0.9851, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 323, Train Loss: 0.0014, Val Loss: 0.6418, Val Score: 0.9808, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 324, Train Loss: 0.0075, Val Loss: 0.3630, Val Score: 0.9883, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 325, Train Loss: 0.0007, Val Loss: 0.4713, Val Score: 0.9867, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 326, Train Loss: 0.0009, Val Loss: 0.4654, Val Score: 0.9867, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 327, Train Loss: 0.0026, Val Loss: 0.4019, Val Score: 0.9864, Best Score: 0.9913\n",
      "Epoch   328: reducing learning rate of group 0 to 2.6352e-04.\n",
      "Time: 3.35, Epoch: 328, Train Loss: 0.0002, Val Loss: 0.4382, Val Score: 0.9871, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 329, Train Loss: 0.0002, Val Loss: 0.4595, Val Score: 0.9873, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 330, Train Loss: 0.0001, Val Loss: 0.4415, Val Score: 0.9875, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 331, Train Loss: 0.0000, Val Loss: 0.5000, Val Score: 0.9858, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 332, Train Loss: 0.0000, Val Loss: 0.4692, Val Score: 0.9885, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 333, Train Loss: 0.0001, Val Loss: 0.5105, Val Score: 0.9867, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 334, Train Loss: 0.0001, Val Loss: 0.5814, Val Score: 0.9854, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 335, Train Loss: 0.0000, Val Loss: 0.5193, Val Score: 0.9863, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 336, Train Loss: 0.0000, Val Loss: 0.5847, Val Score: 0.9856, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 337, Train Loss: 0.0010, Val Loss: 0.5840, Val Score: 0.9841, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 338, Train Loss: 0.0014, Val Loss: 0.6871, Val Score: 0.9831, Best Score: 0.9913\n",
      "Epoch   339: reducing learning rate of group 0 to 2.5034e-04.\n",
      "Time: 3.21, Epoch: 339, Train Loss: 0.0103, Val Loss: 0.6778, Val Score: 0.9829, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 340, Train Loss: 0.0006, Val Loss: 0.6954, Val Score: 0.9834, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 341, Train Loss: 0.0016, Val Loss: 0.4588, Val Score: 0.9890, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 342, Train Loss: 0.0002, Val Loss: 0.5798, Val Score: 0.9856, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 343, Train Loss: 0.0004, Val Loss: 0.5477, Val Score: 0.9879, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 344, Train Loss: 0.0006, Val Loss: 0.6687, Val Score: 0.9833, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 345, Train Loss: 0.0038, Val Loss: 0.5327, Val Score: 0.9857, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 346, Train Loss: 0.0003, Val Loss: 0.5442, Val Score: 0.9862, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 347, Train Loss: 0.0001, Val Loss: 0.6117, Val Score: 0.9854, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 348, Train Loss: 0.0002, Val Loss: 0.5512, Val Score: 0.9867, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 349, Train Loss: 0.0001, Val Loss: 0.7271, Val Score: 0.9810, Best Score: 0.9913\n",
      "Epoch   350: reducing learning rate of group 0 to 2.3783e-04.\n",
      "Time: 3.41, Epoch: 350, Train Loss: 0.0000, Val Loss: 0.6900, Val Score: 0.9804, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 351, Train Loss: 0.0002, Val Loss: 0.6892, Val Score: 0.9825, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 352, Train Loss: 0.0012, Val Loss: 0.5925, Val Score: 0.9861, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 353, Train Loss: 0.0000, Val Loss: 0.5570, Val Score: 0.9854, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 354, Train Loss: 0.0002, Val Loss: 0.7310, Val Score: 0.9794, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 355, Train Loss: 0.0000, Val Loss: 0.7257, Val Score: 0.9805, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 356, Train Loss: 0.0000, Val Loss: 0.6541, Val Score: 0.9859, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 357, Train Loss: 0.0000, Val Loss: 0.6195, Val Score: 0.9863, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 358, Train Loss: 0.0001, Val Loss: 0.7133, Val Score: 0.9825, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 359, Train Loss: 0.0001, Val Loss: 0.7623, Val Score: 0.9803, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 360, Train Loss: 0.0003, Val Loss: 0.8232, Val Score: 0.9816, Best Score: 0.9913\n",
      "Epoch   361: reducing learning rate of group 0 to 2.2594e-04.\n",
      "Time: 3.30, Epoch: 361, Train Loss: 0.0002, Val Loss: 0.9450, Val Score: 0.9771, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 362, Train Loss: 0.0004, Val Loss: 0.5710, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.41, Epoch: 363, Train Loss: 0.0000, Val Loss: 0.6978, Val Score: 0.9825, Best Score: 0.9913\n",
      "Time: 3.44, Epoch: 364, Train Loss: 0.0001, Val Loss: 0.6673, Val Score: 0.9851, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 365, Train Loss: 0.0000, Val Loss: 0.6751, Val Score: 0.9851, Best Score: 0.9913\n",
      "Time: 3.42, Epoch: 366, Train Loss: 0.0000, Val Loss: 0.7470, Val Score: 0.9803, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 367, Train Loss: 0.0000, Val Loss: 0.6930, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 368, Train Loss: 0.0012, Val Loss: 0.6339, Val Score: 0.9826, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 369, Train Loss: 0.0017, Val Loss: 0.6138, Val Score: 0.9877, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 370, Train Loss: 0.0002, Val Loss: 0.6613, Val Score: 0.9826, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 371, Train Loss: 0.0030, Val Loss: 0.6792, Val Score: 0.9849, Best Score: 0.9913\n",
      "Epoch   372: reducing learning rate of group 0 to 2.1464e-04.\n",
      "Time: 3.40, Epoch: 372, Train Loss: 0.0022, Val Loss: 0.8741, Val Score: 0.9767, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 373, Train Loss: 0.0014, Val Loss: 0.6328, Val Score: 0.9821, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 374, Train Loss: 0.0008, Val Loss: 0.5533, Val Score: 0.9867, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 375, Train Loss: 0.0001, Val Loss: 0.6697, Val Score: 0.9826, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 376, Train Loss: 0.0009, Val Loss: 0.5872, Val Score: 0.9831, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 377, Train Loss: 0.0001, Val Loss: 0.5844, Val Score: 0.9845, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 378, Train Loss: 0.0009, Val Loss: 0.7166, Val Score: 0.9833, Best Score: 0.9913\n",
      "Time: 3.41, Epoch: 379, Train Loss: 0.0000, Val Loss: 0.6436, Val Score: 0.9840, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 380, Train Loss: 0.0000, Val Loss: 0.7277, Val Score: 0.9838, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 381, Train Loss: 0.0002, Val Loss: 0.5991, Val Score: 0.9850, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 382, Train Loss: 0.0001, Val Loss: 0.7845, Val Score: 0.9813, Best Score: 0.9913\n",
      "Epoch   383: reducing learning rate of group 0 to 2.0391e-04.\n",
      "Time: 3.42, Epoch: 383, Train Loss: 0.0003, Val Loss: 0.9113, Val Score: 0.9815, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 384, Train Loss: 0.0000, Val Loss: 0.8702, Val Score: 0.9782, Best Score: 0.9913\n",
      "Time: 3.40, Epoch: 385, Train Loss: 0.0000, Val Loss: 0.8534, Val Score: 0.9796, Best Score: 0.9913\n",
      "Time: 3.42, Epoch: 386, Train Loss: 0.0000, Val Loss: 0.8647, Val Score: 0.9777, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 387, Train Loss: 0.0039, Val Loss: 0.6432, Val Score: 0.9832, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 388, Train Loss: 0.0001, Val Loss: 0.6520, Val Score: 0.9853, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 389, Train Loss: 0.0005, Val Loss: 0.7843, Val Score: 0.9823, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 390, Train Loss: 0.0000, Val Loss: 0.7750, Val Score: 0.9804, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 391, Train Loss: 0.0000, Val Loss: 0.7012, Val Score: 0.9790, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 392, Train Loss: 0.0046, Val Loss: 0.6766, Val Score: 0.9809, Best Score: 0.9913\n",
      "Time: 3.36, Epoch: 393, Train Loss: 0.0003, Val Loss: 0.6264, Val Score: 0.9833, Best Score: 0.9913\n",
      "Epoch   394: reducing learning rate of group 0 to 1.9371e-04.\n",
      "Time: 3.31, Epoch: 394, Train Loss: 0.0012, Val Loss: 0.6197, Val Score: 0.9850, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 395, Train Loss: 0.0001, Val Loss: 0.5975, Val Score: 0.9845, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 396, Train Loss: 0.0002, Val Loss: 0.6346, Val Score: 0.9841, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 397, Train Loss: 0.0001, Val Loss: 0.6409, Val Score: 0.9845, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 398, Train Loss: 0.0004, Val Loss: 0.7500, Val Score: 0.9842, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 399, Train Loss: 0.0001, Val Loss: 0.6463, Val Score: 0.9837, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 400, Train Loss: 0.0015, Val Loss: 0.9672, Val Score: 0.9720, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 401, Train Loss: 0.0006, Val Loss: 0.7371, Val Score: 0.9816, Best Score: 0.9913\n",
      "Time: 3.30, Epoch: 402, Train Loss: 0.0000, Val Loss: 0.5926, Val Score: 0.9857, Best Score: 0.9913\n",
      "Time: 3.39, Epoch: 403, Train Loss: 0.0001, Val Loss: 0.7966, Val Score: 0.9815, Best Score: 0.9913\n",
      "Time: 3.35, Epoch: 404, Train Loss: 0.0006, Val Loss: 0.6061, Val Score: 0.9852, Best Score: 0.9913\n",
      "Epoch   405: reducing learning rate of group 0 to 1.8403e-04.\n",
      "Time: 3.34, Epoch: 405, Train Loss: 0.0005, Val Loss: 0.5879, Val Score: 0.9853, Best Score: 0.9913\n",
      "Time: 3.41, Epoch: 406, Train Loss: 0.0000, Val Loss: 0.5703, Val Score: 0.9850, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 407, Train Loss: 0.0005, Val Loss: 0.6864, Val Score: 0.9831, Best Score: 0.9913\n",
      "Time: 3.38, Epoch: 408, Train Loss: 0.0000, Val Loss: 0.5778, Val Score: 0.9877, Best Score: 0.9913\n",
      "Time: 3.37, Epoch: 409, Train Loss: 0.0000, Val Loss: 0.5626, Val Score: 0.9859, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 410, Train Loss: 0.0000, Val Loss: 0.6103, Val Score: 0.9858, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 411, Train Loss: 0.0006, Val Loss: 0.5788, Val Score: 0.9845, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 412, Train Loss: 0.0003, Val Loss: 0.6361, Val Score: 0.9831, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 413, Train Loss: 0.0006, Val Loss: 0.7523, Val Score: 0.9831, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 414, Train Loss: 0.0008, Val Loss: 0.6039, Val Score: 0.9849, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 415, Train Loss: 0.0000, Val Loss: 0.7029, Val Score: 0.9824, Best Score: 0.9913\n",
      "Epoch   416: reducing learning rate of group 0 to 1.7482e-04.\n",
      "Time: 3.29, Epoch: 416, Train Loss: 0.0000, Val Loss: 0.6945, Val Score: 0.9825, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 417, Train Loss: 0.0001, Val Loss: 0.6511, Val Score: 0.9863, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 418, Train Loss: 0.0001, Val Loss: 0.6548, Val Score: 0.9842, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 419, Train Loss: 0.0004, Val Loss: 0.7560, Val Score: 0.9789, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 420, Train Loss: 0.0006, Val Loss: 0.7806, Val Score: 0.9781, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 421, Train Loss: 0.0000, Val Loss: 0.8916, Val Score: 0.9782, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 422, Train Loss: 0.0001, Val Loss: 0.6942, Val Score: 0.9798, Best Score: 0.9913\n",
      "Time: 3.34, Epoch: 423, Train Loss: 0.0001, Val Loss: 0.8167, Val Score: 0.9783, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 424, Train Loss: 0.0000, Val Loss: 0.9408, Val Score: 0.9782, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 425, Train Loss: 0.0000, Val Loss: 0.8081, Val Score: 0.9787, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 426, Train Loss: 0.0000, Val Loss: 0.8957, Val Score: 0.9767, Best Score: 0.9913\n",
      "Epoch   427: reducing learning rate of group 0 to 1.6608e-04.\n",
      "Time: 3.25, Epoch: 427, Train Loss: 0.0000, Val Loss: 0.7794, Val Score: 0.9819, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 428, Train Loss: 0.0000, Val Loss: 0.6856, Val Score: 0.9839, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 429, Train Loss: 0.0000, Val Loss: 0.7512, Val Score: 0.9799, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 430, Train Loss: 0.0006, Val Loss: 0.8953, Val Score: 0.9755, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 431, Train Loss: 0.0001, Val Loss: 1.1444, Val Score: 0.9739, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 432, Train Loss: 0.0000, Val Loss: 0.8464, Val Score: 0.9771, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 433, Train Loss: 0.0000, Val Loss: 0.7717, Val Score: 0.9811, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 434, Train Loss: 0.0102, Val Loss: 0.7855, Val Score: 0.9804, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 435, Train Loss: 0.0001, Val Loss: 0.8041, Val Score: 0.9816, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 436, Train Loss: 0.0027, Val Loss: 0.7499, Val Score: 0.9858, Best Score: 0.9913\n",
      "Time: 3.23, Epoch: 437, Train Loss: 0.0000, Val Loss: 0.7180, Val Score: 0.9842, Best Score: 0.9913\n",
      "Epoch   438: reducing learning rate of group 0 to 1.5778e-04.\n",
      "Time: 3.29, Epoch: 438, Train Loss: 0.0000, Val Loss: 0.8158, Val Score: 0.9825, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 439, Train Loss: 0.0018, Val Loss: 0.6952, Val Score: 0.9832, Best Score: 0.9913\n",
      "Time: 3.18, Epoch: 440, Train Loss: 0.0000, Val Loss: 0.6984, Val Score: 0.9855, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 441, Train Loss: 0.0000, Val Loss: 0.7034, Val Score: 0.9836, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 442, Train Loss: 0.0000, Val Loss: 0.7542, Val Score: 0.9814, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 443, Train Loss: 0.0000, Val Loss: 0.7243, Val Score: 0.9836, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 444, Train Loss: 0.0008, Val Loss: 0.7416, Val Score: 0.9803, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 445, Train Loss: 0.0000, Val Loss: 0.8053, Val Score: 0.9777, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 446, Train Loss: 0.0009, Val Loss: 0.8109, Val Score: 0.9798, Best Score: 0.9913\n",
      "Time: 3.23, Epoch: 447, Train Loss: 0.0000, Val Loss: 0.7743, Val Score: 0.9789, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 448, Train Loss: 0.0007, Val Loss: 0.7556, Val Score: 0.9834, Best Score: 0.9913\n",
      "Epoch   449: reducing learning rate of group 0 to 1.4989e-04.\n",
      "Time: 3.28, Epoch: 449, Train Loss: 0.0000, Val Loss: 0.7377, Val Score: 0.9814, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 450, Train Loss: 0.0000, Val Loss: 0.6309, Val Score: 0.9868, Best Score: 0.9913\n",
      "Time: 3.22, Epoch: 451, Train Loss: 0.0011, Val Loss: 0.7180, Val Score: 0.9807, Best Score: 0.9913\n",
      "Time: 3.32, Epoch: 452, Train Loss: 0.0000, Val Loss: 0.7261, Val Score: 0.9847, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 453, Train Loss: 0.0024, Val Loss: 0.5298, Val Score: 0.9855, Best Score: 0.9913\n",
      "Time: 3.22, Epoch: 454, Train Loss: 0.0000, Val Loss: 0.5395, Val Score: 0.9873, Best Score: 0.9913\n",
      "Time: 3.21, Epoch: 455, Train Loss: 0.0000, Val Loss: 0.5969, Val Score: 0.9853, Best Score: 0.9913\n",
      "Time: 3.19, Epoch: 456, Train Loss: 0.0008, Val Loss: 0.6186, Val Score: 0.9825, Best Score: 0.9913\n",
      "Time: 3.17, Epoch: 457, Train Loss: 0.0002, Val Loss: 0.6034, Val Score: 0.9843, Best Score: 0.9913\n",
      "Time: 3.15, Epoch: 458, Train Loss: 0.0001, Val Loss: 0.5582, Val Score: 0.9864, Best Score: 0.9913\n",
      "Time: 3.19, Epoch: 459, Train Loss: 0.0003, Val Loss: 0.5444, Val Score: 0.9868, Best Score: 0.9913\n",
      "Epoch   460: reducing learning rate of group 0 to 1.4240e-04.\n",
      "Time: 3.20, Epoch: 460, Train Loss: 0.0000, Val Loss: 0.6796, Val Score: 0.9798, Best Score: 0.9913\n",
      "Time: 3.19, Epoch: 461, Train Loss: 0.0002, Val Loss: 0.7440, Val Score: 0.9812, Best Score: 0.9913\n",
      "Time: 3.22, Epoch: 462, Train Loss: 0.0051, Val Loss: 0.5792, Val Score: 0.9846, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 463, Train Loss: 0.0000, Val Loss: 0.6399, Val Score: 0.9847, Best Score: 0.9913\n",
      "Time: 3.21, Epoch: 464, Train Loss: 0.0009, Val Loss: 0.6921, Val Score: 0.9847, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 465, Train Loss: 0.0000, Val Loss: 0.8115, Val Score: 0.9805, Best Score: 0.9913\n",
      "Time: 3.33, Epoch: 466, Train Loss: 0.0072, Val Loss: 0.7150, Val Score: 0.9874, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 467, Train Loss: 0.0007, Val Loss: 0.4989, Val Score: 0.9878, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 468, Train Loss: 0.0007, Val Loss: 0.5946, Val Score: 0.9851, Best Score: 0.9913\n",
      "Time: 3.19, Epoch: 469, Train Loss: 0.0000, Val Loss: 0.5654, Val Score: 0.9855, Best Score: 0.9913\n",
      "Time: 3.17, Epoch: 470, Train Loss: 0.0001, Val Loss: 0.5960, Val Score: 0.9829, Best Score: 0.9913\n",
      "Epoch   471: reducing learning rate of group 0 to 1.3528e-04.\n",
      "Time: 3.23, Epoch: 471, Train Loss: 0.0001, Val Loss: 0.5541, Val Score: 0.9869, Best Score: 0.9913\n",
      "Time: 3.21, Epoch: 472, Train Loss: 0.0000, Val Loss: 0.6143, Val Score: 0.9863, Best Score: 0.9913\n",
      "Time: 3.22, Epoch: 473, Train Loss: 0.0001, Val Loss: 0.7088, Val Score: 0.9827, Best Score: 0.9913\n",
      "Time: 3.30, Epoch: 474, Train Loss: 0.0002, Val Loss: 0.6360, Val Score: 0.9840, Best Score: 0.9913\n",
      "Time: 3.22, Epoch: 475, Train Loss: 0.0000, Val Loss: 0.6925, Val Score: 0.9824, Best Score: 0.9913\n",
      "Time: 3.18, Epoch: 476, Train Loss: 0.0000, Val Loss: 0.4977, Val Score: 0.9876, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 477, Train Loss: 0.0001, Val Loss: 0.5944, Val Score: 0.9851, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 478, Train Loss: 0.0001, Val Loss: 0.6715, Val Score: 0.9875, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 479, Train Loss: 0.0014, Val Loss: 0.6092, Val Score: 0.9845, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 480, Train Loss: 0.0015, Val Loss: 0.6764, Val Score: 0.9827, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 481, Train Loss: 0.0001, Val Loss: 0.5849, Val Score: 0.9887, Best Score: 0.9913\n",
      "Epoch   482: reducing learning rate of group 0 to 1.2851e-04.\n",
      "Time: 3.28, Epoch: 482, Train Loss: 0.0000, Val Loss: 0.5795, Val Score: 0.9860, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 483, Train Loss: 0.0000, Val Loss: 0.5301, Val Score: 0.9882, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 484, Train Loss: 0.0000, Val Loss: 0.5588, Val Score: 0.9875, Best Score: 0.9913\n",
      "Time: 3.29, Epoch: 485, Train Loss: 0.0000, Val Loss: 0.6261, Val Score: 0.9865, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 486, Train Loss: 0.0000, Val Loss: 0.6863, Val Score: 0.9838, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 487, Train Loss: 0.0000, Val Loss: 0.6358, Val Score: 0.9874, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 488, Train Loss: 0.0000, Val Loss: 0.7025, Val Score: 0.9842, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 489, Train Loss: 0.0000, Val Loss: 0.6887, Val Score: 0.9846, Best Score: 0.9913\n",
      "Time: 3.15, Epoch: 490, Train Loss: 0.0000, Val Loss: 0.6723, Val Score: 0.9848, Best Score: 0.9913\n",
      "Time: 3.26, Epoch: 491, Train Loss: 0.0000, Val Loss: 0.7533, Val Score: 0.9810, Best Score: 0.9913\n",
      "Time: 3.28, Epoch: 492, Train Loss: 0.0010, Val Loss: 0.7988, Val Score: 0.9795, Best Score: 0.9913\n",
      "Epoch   493: reducing learning rate of group 0 to 1.2209e-04.\n",
      "Time: 3.30, Epoch: 493, Train Loss: 0.0000, Val Loss: 0.7662, Val Score: 0.9816, Best Score: 0.9913\n",
      "Time: 3.27, Epoch: 494, Train Loss: 0.0000, Val Loss: 0.8364, Val Score: 0.9801, Best Score: 0.9913\n",
      "Time: 3.24, Epoch: 495, Train Loss: 0.0000, Val Loss: 0.7645, Val Score: 0.9801, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 496, Train Loss: 0.0000, Val Loss: 0.7806, Val Score: 0.9815, Best Score: 0.9913\n",
      "Time: 3.19, Epoch: 497, Train Loss: 0.0000, Val Loss: 0.7263, Val Score: 0.9822, Best Score: 0.9913\n",
      "Time: 3.20, Epoch: 498, Train Loss: 0.0032, Val Loss: 0.6902, Val Score: 0.9850, Best Score: 0.9913\n",
      "Time: 3.25, Epoch: 499, Train Loss: 0.0000, Val Loss: 0.7847, Val Score: 0.9804, Best Score: 0.9913\n",
      "Time: 3.31, Epoch: 500, Train Loss: 0.0000, Val Loss: 0.7369, Val Score: 0.9835, Best Score: 0.9913\n",
      "Test Score: 0.975823\n"
     ]
    }
   ],
   "source": [
    "!python main_dropout.py --dataset_file './data/human/human_transformer12.npz' --save_model './saved_models' --save_result './results'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PretrainDPI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
