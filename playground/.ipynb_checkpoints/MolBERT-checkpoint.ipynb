{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KADJyDz-juRA"
   },
   "source": [
    "## MolBERT: Molecular representation learning with language models and domain-relevant auxiliary tasks\n",
    "\n",
    "ABSTRACT: We apply a Transformer architecture, specifically BERT, to learn flexible and\n",
    "high quality molecular representations for drug discovery problems, and study the\n",
    "impact of using different combinations of self-supervised tasks for pre-training.\n",
    "Our results on established Virtual Screening and QSAR benchmarks show that: i) The selection of appropriate self-supervised task(s) for pre-training has a significant\n",
    "impact on performance in subsequent downstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more domain relevance for Chemistry, such as learning to predict calculated molecular properties, increases the fidelity of our learnt representations. iii) Finally, we show that molecular representations learnt by\n",
    "our model ‘MOLBERT’ improve upon the current state of the art on the benchmark\n",
    "datasets.\n",
    "\n",
    "Link to paper: https://arxiv.org/pdf/2011.13230v1.pdf\n",
    "\n",
    "Credit: https://github.com/BenevolentAI/MolBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J464_W87jbmH",
    "outputId": "facf9738-0f73-4674-88b6-6afff88bcce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/MolBERT\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository and cd into directory\n",
    "!git clone https://github.com/BenevolentAI/MolBERT.git\n",
    "%cd MolBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynly6NE9kCdq"
   },
   "outputs": [],
   "source": [
    "# Install requirements / dependencies\n",
    "!pip install -e .\n",
    "\n",
    "# Install torchvision\n",
    "!pip install torchvision==0.6.0 torchtext==0.6.0\n",
    "\n",
    "# Install RDKit \n",
    "!pip install rdkit-pypi==2021.3.1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wj-8ErC3lT5n"
   },
   "source": [
    "### Load pretrained model\n",
    "You can download the pretrained model [here](https://ndownloader.figshare.com/files/25611290)\n",
    "\n",
    "After downloading the weights, you can follow `scripts/featurize.py` to load the model and use it as a featurizer (you just need to replace the path in the script)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsvxhCAilZ_-"
   },
   "source": [
    "### Train model from scratch:\n",
    "\n",
    "You can use the guacamol dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L9F0xDpohhA"
   },
   "outputs": [],
   "source": [
    "# download the guacamol dataset\n",
    "!wget https://raw.githubusercontent.com/BenevolentAI/guacamol_baselines/master/fetch_guacamol_dataset.sh\n",
    "!sh fetch_guacamol_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc_t5XPrkat4"
   },
   "outputs": [],
   "source": [
    "!python molbert/apps/smiles.py \\\n",
    "    --train_file data/guacamol_v1_train.smiles \\\n",
    "    --valid_file data/guacamol_v1_valid.smiles \\\n",
    "    --max_seq_length 128 \\\n",
    "    --batch_size 64 \\\n",
    "    --masked_lm 1 \\\n",
    "    --max_epochs 20 \\\n",
    "    --num_workers 8 \\\n",
    "    --val_check_interval 1 \\\n",
    "    --gpus 1 \\\n",
    "    --tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_YYRqq2lnBW"
   },
   "source": [
    "Add the `--tiny` flag to train a smaller model on a CPU, or the `--fast_dev_run` flag for testing purposes. For full list of options see `molbert/apps/args.py` and `molbert/apps/smiles.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgjvpb4uaqvX"
   },
   "source": [
    "### Finetune\n",
    "\n",
    "After you have trained a model, and you would like to finetune on a certain training set, you can use the `FinetuneSmilesMolbertApp` class to further specialize your model to your task.\n",
    "\n",
    "For classification you can set can set the mode to `classification` and the `output_size` to 2.\n",
    "\n",
    "To reproduce the finetuning experiments we direct you to use `scripts/run_qsar_test_molbert.py` and `scripts/run_finetuning.py`. \n",
    "Both scripts rely on the [Chembench](https://github.com/shenwanxiang/ChemBench) and optionally the [CDDD](https://github.com/jrwnter/cddd) repositories. \n",
    "Please follow the installation instructions described in their READMEs.\n",
    "\n",
    "```shell script\n",
    "python molbert/apps/finetune.py \\\n",
    "    --train_file path/to/train.csv \\\n",
    "    --valid_file path/to/valid.csv \\\n",
    "    --test_file path/to/test.csv \\\n",
    "    --mode classification \\\n",
    "    --output_size 2 \\\n",
    "    --pretrained_model_path path/to/lightning_logs/version_0/checkpoints/last.ckpt \\\n",
    "    --label_column my_label_column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sqd_SrrOa8wk"
   },
   "source": [
    "For regression set the mode to `regression` and the `output_size` to 1.\n",
    "\n",
    "```shell script\n",
    "python molbert/apps/finetune.py \\\n",
    "    --train_file path/to/train.csv \\\n",
    "    --valid_file path/to/valid.csv \\\n",
    "    --test_file path/to/test.csv \\\n",
    "    --mode regression \\\n",
    "    --output_size 1 \\\n",
    "    --pretrained_model_path path/to/lightning_logs/version_0/checkpoints/last.ckpt \\\n",
    "    --label_column pIC50\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmobT72EcY9I"
   },
   "source": [
    "To reproduce the finetuning experiments we direct you to use `scripts/run_qsar_test_molbert.py` and `scripts/run_finetuning.py`. \n",
    "Both scripts rely on the [Chembench](https://github.com/shenwanxiang/ChemBench) and optionally the [CDDD](https://github.com/jrwnter/cddd) repositories. \n",
    "Please follow the installation instructions described in their READMEs."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MolBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
