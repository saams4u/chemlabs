{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HOKCrJ-YQrt"
   },
   "source": [
    "## MAT: Molecule Attention Transformer\n",
    "\n",
    "ABSTRACT: Designing a single neural network architecture that performs competitively across a range\n",
    "of molecule property prediction tasks remains\n",
    "largely an open challenge, and its solution may unlock a widespread use of deep learning in the drug discovery industry. To move towards this goal, we propose Molecule Attention Transformer (MAT). Our key innovation is to augment the attention mechanism in Transformer using inter-atomic distances and the molecular graph structure. Experiments show that MAT performs competitively on a diverse set of molecular prediction tasks. Most importantly, with a simple self-supervised pretraining, MAT requires tuning of only a few hyperparameter values to achieve state-of-the-art performance on downstream tasks. Finally, we show that attention weights learned by MAT are interpretable from the chemical point of view.\n",
    "\n",
    "Link to paper: https://arxiv.org/pdf/2002.08264v1.pdf\n",
    "\n",
    "Credit: https://github.com/ardigen/MAT\n",
    "\n",
    "Google Colab: https://colab.research.google.com/drive/1285XO7B0BEJ4gZkb1TP_SqMnGIDvGw3B?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yQyp8jIYODR",
    "outputId": "4767a881-6027-4be1-af14-d37de10798e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/MAT/src\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository and cd into directory\n",
    "!git clone https://github.com/ardigen/MAT.git\n",
    "%cd MAT/src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rwOLZT1Yxvz"
   },
   "source": [
    "### Example of loading pretrained weights into MA\n",
    "\n",
    "#### Prepare Data Set\n",
    "\n",
    "First, a data set is loaded. Function <code>load_data_from_df</code> automatically saves calculated features to the provided data directory (unless <code>use_data_saving</code> is set to <code>False</code>). Every next run will use the saved features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kaydVu00Yr3w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "os.chdir('MAT/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnME85Z3ZT_f",
    "outputId": "49c9afe6-6e03-4078-a54d-6abf3a0d7df4"
   },
   "outputs": [],
   "source": [
    "# Install RDKit \n",
    "!pip install rdkit-pypi==2021.3.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MdiwBXcXZQwc"
   },
   "outputs": [],
   "source": [
    "from featurization.data_utils import load_data_from_df, construct_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "keK3XTxbZSwv"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Formal charges are one-hot encoded to keep compatibility with the pre-trained weights.\n",
    "# If you do not plan to use the pre-trained weights, we recommend to set one_hot_formal_charge to False.\n",
    "X, y = load_data_from_df('../data/freesolv/freesolv.csv', one_hot_formal_charge=True)\n",
    "data_loader = construct_loader(X, y, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHh2IpkhaOIH"
   },
   "source": [
    "You can use your data, but the CSV file should contain two columns as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "Ee3Lk4DIaK6B",
    "outputId": "dc74d541-0a3e-4555-e610-e21aa143114d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN(C)C(=O)c1ccc(cc1)OC</td>\n",
       "      <td>-1.874467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-0.277514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)C=C</td>\n",
       "      <td>1.465089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCc1cnccn1</td>\n",
       "      <td>-0.428367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCCO</td>\n",
       "      <td>-0.105855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   smiles         y\n",
       "0  CN(C)C(=O)c1ccc(cc1)OC -1.874467\n",
       "1            CS(=O)(=O)Cl -0.277514\n",
       "2                CC(C)C=C  1.465089\n",
       "3              CCc1cnccn1 -0.428367\n",
       "4                CCCCCCCO -0.105855"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/freesolv/freesolv.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7sHbKCbaSpw"
   },
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b5IXxcmiaP5r"
   },
   "outputs": [],
   "source": [
    "from transformer import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gUEzKF7GabB1"
   },
   "outputs": [],
   "source": [
    "d_atom = X[0][0].shape[1]  # It depends on the used featurization.\n",
    "\n",
    "model_params = {\n",
    "    'd_atom': d_atom,\n",
    "    'd_model': 1024,\n",
    "    'N': 8,\n",
    "    'h': 16,\n",
    "    'N_dense': 1,\n",
    "    'lambda_attention': 0.33, \n",
    "    'lambda_distance': 0.33,\n",
    "    'leaky_relu_slope': 0.1, \n",
    "    'dense_output_nonlinearity': 'relu', \n",
    "    'distance_matrix_kernel': 'exp', \n",
    "    'dropout': 0.0,\n",
    "    'aggregation_type': 'mean'\n",
    "}\n",
    "\n",
    "model = make_model(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8spqXq2FaiAm"
   },
   "source": [
    "### Load Pretrained Weights (optional)\n",
    "\n",
    "If you want to use the pre-trained weights to train your model, <b>you should not change model parameters in the cell above</b>.\n",
    "\n",
    "First, download the pretrained weights: https://drive.google.com/file/d/11-TZj8tlnD7ykQGliO9bCrySJNBnYD2k/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KeWE-diPadua"
   },
   "outputs": [],
   "source": [
    "pretrained_name = '../pretrained_weights.pt'\n",
    "pretrained_state_dict = torch.load(pretrained_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4p_D4e_Qap6I"
   },
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()\n",
    "\n",
    "for name, param in pretrained_state_dict.items():\n",
    "    if 'generator' in name:\n",
    "         continue\n",
    "    if isinstance(param, torch.nn.Parameter):\n",
    "        param = param.data\n",
    "    model_state_dict[name].copy_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJX__jrHbgoG"
   },
   "source": [
    "#### Run Training/Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SPzkWdFbbhOH"
   },
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "\n",
    "for batch in data_loader:\n",
    "    adjacency_matrix, node_features, distance_matrix, y = batch\n",
    "    batch_mask = torch.sum(torch.abs(node_features), dim=-1) != 0\n",
    "    output = model(node_features, batch_mask, adjacency_matrix, distance_matrix, None)\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MAT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
